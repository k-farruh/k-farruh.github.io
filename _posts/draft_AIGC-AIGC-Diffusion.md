---
title: 'Diffusion Graphic Generation Solution From Alibaba Cloud'
date: draft_AIGC
permalink: /posts/draft_A/AIGC-Diffusion/
tags:
  - cool posts
  - category1
  - category2
---

AIGC-Diffusion Graphic Generation Solution from Alibaba Cloud
 \* {
 font-family: Georgia, Cambria, "Times New Roman", Times, serif;
 }
 html, body {
 margin: 0;
 padding: 0;
 }
 h1 {
 font-size: 50px;
 margin-bottom: 17px;
 color: #333;
 }
 h2 {
 font-size: 24px;
 line-height: 1.6;
 margin: 30px 0 0 0;
 margin-bottom: 18px;
 margin-top: 33px;
 color: #333;
 }
 h3 {
 font-size: 30px;
 margin: 10px 0 20px 0;
 color: #333;
 }
 header {
 width: 640px;
 margin: auto;
 }
 section {
 width: 640px;
 margin: auto;
 }
 section p {
 margin-bottom: 27px;
 font-size: 20px;
 line-height: 1.6;
 color: #333;
 }
 section img {
 max-width: 640px;
 }
 footer {
 padding: 0 20px;
 margin: 50px 0;
 text-align: center;
 font-size: 12px;
 }
 .aspectRatioPlaceholder {
 max-width: auto !important;
 max-height: auto !important;
 }
 .aspectRatioPlaceholder-fill {
 padding-bottom: 0 !important;
 }
 header,
 section[data-field=subtitle],
 section[data-field=description] {
 display: none;
 }
 

AIGC-Diffusion Graphic Generation Solution from Alibaba Cloud
=============================================================




Write here how the AIGC models are popular and what they can do.




---

### AIGC-Diffusion Graphic Generation Solution from Alibaba Cloud

**Write here how the AIGC models are popular and what they can do.**

Day-by-day **AI-generated Content** (AIGC) models are becoming popular by showing their capabilities. The astonishing rise of AIGC models reveals both its usefulness in helping with a wide range of tasks and a general overflowing curiosity about human-like machines. So, in this article, we show how to make your own AIGC model without spending millions of dollars and thousands of hours to create the model with good results. Everyone knows that training and inference the language-based models like [BERT](https://arxiv.org/abs/1810.04805) and [GPT](https://www.alibabacloud.com/blog/599666) will be expensive regarding hardware (GPU-Graphics Processing Unit) usage. Hence, as an example model, we will run stable diffusion text and image generation solution. The relevant information can be found [here](https://www.alibabacloud.com/blog/599498) if you would like to know more about stable diffusion.

The Diffusion text-to-image generation solution is based on Alibaba Cloud's [Machine Learning PAI](https://www.alibabacloud.com/product/machine-learning) (Platform for AI) product, which helps you quickly build an end-to-end full-link construction process, including offline model training and inference, and realizes the function of generating images from text. 

### Background Information

Alibaba Cloud machine learning PAI provides an end-to-end, diversified pure white box solution in the field of text and image generation and creation and currently supports the Chinese text and image generation function. You can customize and build an intelligent text-image generation model according to your business scenarios or use the default model provided by PAI for model tuning and online deployment to generate images of different styles for different text inputs. The specific solution is as follows.

1. Based on the Diffusion model and algorithm provided by PAI, according to your text-image generation scenarios, fine-tune the model on the PAI-DSW platform to build a Diffusion text-image generation model for specific scenarios.
2. You can deploy the model generated by fine-tuning or PAI's default Diffusion model as the PAI-EAS online service to generate corresponding images from the input text.

The solution supports the following two usages:

Method 1: Use the PAI-Diffusion model

* Deploy the PAI default model directly as PAI-EAS online service, and call the model service for online debugging.

Method 2: Use the fine-tuned PAI-Diffusion model

* In the text graph generation solution, the process of fine-tuning and deploying the PAI-Diffusion model is as follows.

![](https://cdn-images-1.medium.com/max/800/1*269bqJRePlPWBvsP8UOfow.png)  


[Step 1: Prepare data](https://help.aliyun.com/document_detail/606223.html?spm=5176.21213303.J_6704733920.30.302f53c9BtqegK&scm=20140722.S_help%40%40%E6%96%87%E6%A1%A3%40%40606223._.ID_help%40%40%E6%96%87%E6%A1%A3%40%40606223-RL_%E4%BD%BF%E7%94%A8stableDASdiffusion%E7%94%9F%E6%88%90%E8%A7%86%E9%A2%91%E7%9A%84%E5%AE%8C%E6%95%B4%E6%95%99%E7%A8%8B-LOC_main-OR_ser-V_2-P0_4#809d2841b3mw2)

Upload the training data set and verification data set to the OSS Bucket for subsequent training of the graph generation model.

[Step 2: Construct a text-graph generation model](https://help.aliyun.com/document_detail/606223.html?spm=5176.21213303.J_6704733920.30.302f53c9BtqegK&scm=20140722.S_help%40%40%E6%96%87%E6%A1%A3%40%40606223._.ID_help%40%40%E6%96%87%E6%A1%A3%40%40606223-RL_%E4%BD%BF%E7%94%A8stableDASdiffusion%E7%94%9F%E6%88%90%E8%A7%86%E9%A2%91%E7%9A%84%E5%AE%8C%E6%95%B4%E6%95%99%E7%A8%8B-LOC_main-OR_ser-V_2-P0_4#68b9e041b3ctp)

On the PAI-DSW platform, use the text-image generation model to fine-tune NoteBook and build the text-image generation model.

[Step 3: Deploy and call model service](https://help.aliyun.com/document_detail/606223.html?spm=5176.21213303.J_6704733920.30.302f53c9BtqegK&scm=20140722.S_help%40%40%E6%96%87%E6%A1%A3%40%40606223._.ID_help%40%40%E6%96%87%E6%A1%A3%40%40606223-RL_%E4%BD%BF%E7%94%A8stableDASdiffusion%E7%94%9F%E6%88%90%E8%A7%86%E9%A2%91%E7%9A%84%E5%AE%8C%E6%95%B4%E6%95%99%E7%A8%8B-LOC_main-OR_ser-V_2-P0_4#6da492d0b39wd)

Through the model online service PAI-EAS, you can deploy the trained text-image generation model as an online service and call it in the actual production environment to realize online image generation.

### prerequisite

Before starting, please make sure you have completed the following preparations:

* You have subscribed to PAI (Designer, DSW, EAS) and paid afterward, and created a default workspace. For details, see [Activate and Create a Default Workspace](https://help.aliyun.com/document_detail/326190.htm) .
* An OSS storage space (Bucket) has been created to store datasets, model files obtained from training, and configuration files. For details on how to create a storage space, see [Creating a Storage Space](https://help.aliyun.com/document_detail/31885.htm) .
* (Optional) A DSW instance has been created and is running normally. For details, see [Creating and Managing a DSW Instance](https://help.aliyun.com/document_detail/163684.htm) .
* A dedicated resource group for PAI-EAS has been created to deploy the trained model. For details on how to create a dedicated resource group, see [Using a dedicated resource group](https://help.aliyun.com/document_detail/120122.htm) .
* When using PAI's default Diffusion model to deploy services, you need to create a resource group machine with an A10 or A100 card type.
* When using the fine-tuned Finetune model to deploy services, it is necessary to create resource group machines of card types such as T4, V100, A10, or A100.

### Method 1: Use the PAI-Diffusion model

### Step 1: Deploy the service

If you want to deploy the PAI-Diffusion model directly, you can deploy the default model provided by PAI as an online service. The specific steps are as follows.

1. Enter **the PAI EAS model online service** page.
2. Log in to [the PAI console](https://pai.console.aliyun.com/) .
3. **Click the workspace list** in the left navigation bar , and click the name of the workspace to be operated on the workspace list page to enter the corresponding workspace.
4. In the left navigation bar of the workspace page, select **Model Deployment > Model Online Service (EAS)** to enter **the PAI EAS Model Online Service** page.
5. On the **Inference Service** tab, click **Deploy Service** .
6. On **the Deploy Service** page, configure parameters and click **Deploy** .

![](https://cdn-images-1.medium.com/max/800/1*k_rfnFyCGAZdDiDfPSTmXg.png)1. Paste the content of the following JSON file into the text box under the **corresponding configuration edit .**


```
{  

```
* **name** : need to be replaced with your own service name, you can directly modify this parameter in the console **model service information area.**
* **resource** : It needs to be replaced with your own resource group. You can directly modify this parameter in the **resource deployment information area of ​​the console.**
* **illustrate**
* A resource group machine with an A10 or A100 card type is required.

### Step 2: Call the service

The service provides a RESTful API, and the specific Python call example is as follows.


```
import json  
import sys  
import requests  
  
import base64  
from io import BytesIO  
from PIL import Image  
import os  
from PIL import PngImagePlugin  
  
hosts = '<Replace with your service call address>' # Service address, which can be obtained in the call information under the service method column of the target service.  
head = {  
 "Authorization": "<Replace with your service token>" # Service authentication information, which can be obtained in the call information under the service method column of the target service.  
}  
  
def decode\_base64(image\_base64, save\_file):  
 img = Image.open(BytesIO(base64.urlsafe\_b64decode(image\_base64)))  
 img.save(save\_file)  
  
  
datas = json.dumps({  
 "text": "a cat playing the guitar",   
 "skip\_translation": False,  
 "num\_inference\_steps": 20,  
 "num\_images": 1,  
 "use\_blade": True,  
 }  
)  
  
r = requests.post(hosts, data=datas, headers=head)  
data = json.loads(r.content.decode('utf-8'))  
  
text = data["text"]  
images\_base64 = data["images\_base64"]  
success = data["success"]  
error = data["error"]  
print("text: " + text)  
print("num\_images:" + str(len(images\_base64)))  
  
decode\_base64(images\_base64[0], "./decode\_ldm\_base64.png")
```
The service call parameters are configured as follows.

![](https://cdn-images-1.medium.com/max/800/1*sQqptIsMy1swrBgOq0LE6A.png)The service return parameters are described as follows.

![](https://cdn-images-1.medium.com/max/800/1*DG8CHwcdatIbupC1frctwQ.png)### Method 2: Use the fine-tuned PAI-Diffusion model

### Step 1: Prepare data

1. Prepare training and validation datasets.

This article uses a subset of a Chinese text and image dataset for model training. The specific format requirements of the training data set and the verification data set are as follows.

1. Data: Training dataset; Format: TSV; Columns: text column, Image column (base64 encoded); File: [T2I\_train.tsv](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/file-manage-files/zh-CN/20230223/mchs/T2I_train.tsv).
2. Data: Validation dataset; Format: TSV; Columns: text column, Image column (base64 encoded); File: [T2I\_val.tsv](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/file-manage-files/zh-CN/20230223/wuti/T2I_val.tsv)

2. Upload the dataset to the OSS Bucket. For details, see [Uploading Files](https://help.aliyun.com/document_detail/31886.htm) .

### Step 2: Construct a text-graph generation model

1. Enter DSW Gallery, see [Function Trial: DSW Gallery](https://help.aliyun.com/document_detail/441723.htm) for details .
2. In the **Chinese text-image generation** area based on the EasyNLP Diffusion model on the **Deep Learning** tab , click **Open in DSW** , and follow the console operation instructions to build a text-image generation model, namely the Finetune model.

![](https://cdn-images-1.medium.com/max/800/0*FedMmqV1j8_nVaBG.png)3. Package the trained model and other related configuration files. Package the trained model and other configuration files into tar.gz format, and upload them to the user's OSS Bucket. The directory structure for models and configurations is shown in the figure below.

![](https://cdn-images-1.medium.com/max/800/0*Frched_3ITq7xEvo.png)You can use the following command to pack the directory into tar.gz format.


```
cd finetuned\_model/   
tar czf finetuned\_model.tar.gz config.json pytorch\_model.bin RRDB\_ESRGAN\_x4.pth vocab.txt
```
**finetuned\_model.tar.gz** is the packaged model file.

### Step 3: Deploy and call model service

1. Deploy the model service.
2. Refer to Step 1: Deploy the service, paste the content of the following JSON file into the text box under the **corresponding configuration edit, and deploy the Finetune model service.**


```
{  
 "baseimage": "registry.cn-shanghai.aliyuncs.com/eas/eas-worker-amd64:0.6.8",  
 "data\_image": "registry.cn-shanghai.aliyuncs.com/pai-ai-test/eas-service:ch\_ldm\_v100",  
 "metadata": {  
 "cpu": 15,  
 "gpu": 1,  
 "instance": 1,  
 "memory": 50000,  
 "resource": "<请替换成自己的资源组>",  
 "rpc": {  
 "keepalive": 50000,  
 "worker\_threads": 5  
 }  
 },  
 "model\_path": "<请替换成finetune后打包并上传到OSS的模型文件>",  
 "processor\_entry": "./app.py",  
 "processor\_path": "http://pai-vision-exp.oss-cn-zhangjiakou.aliyuncs.com/wzh-zhoulou/dl\_eas\_processor/ch\_ldm/ch\_ldm\_blade\_220206/eas\_processor\_20230206.tar.gz",  
 "processor\_type": "python",  
 "name": "<自己的服务名称>"  
}
```
in:

* **model\_path**: It needs to be replaced with the storage path of the packaged model file in the OSS Bucket.
* **name**: need to be replaced with your own service name. You can directly modify this parameter in the console **model service information area.**
* **resource**: It needs to be replaced with your own resource group. You can directly modify this parameter in the **resource deployment information area of ​​the console.**

**illustrate** The Finetune model supports resource group machines using card types such as T4, V100, A10, and A100.

2. Call the model service.

Refer to Step 2: Invoke the service to call the Finetune model service. Among them: **text** only supports Chinese text input; service call parameters do not support configuration **skip\_translation**.

  




[View original.](https://medium.com/p/b317ff2366f4)

Exported from [Medium](https://medium.com) on May 25, 2024.

